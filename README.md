# NeuralNetwork
Описание работы нейронной сети
Нейронная сеть обучалась на открытом дата сете MNIST.
Нейронная сеть состоит из 4 слоев: входной слой на 784 нейрона, первый скрытый слой на 16 нейронов, второй скрытый слой на 16 нейронов, выходной слой на 10 нейронов.
Описание работы функций:
	double ReLU – функция активации на слоях 2 и 3.
	void SoftMax – преобразует вектор ответов на выходном слое в вектор вероятностей
	vector<double> BoolVector – возвращает вектор ожидаемого распределения вероятностей
	double CrossEntropy - функция вычисления ошибки
	void ReadData – функция чтения обучающей выборки из файла
	void ReadDataTest – функция чтения тестовой выборки из файла
	vector<double> elementalSubstraction – функция поэлементного вычитания векторов
	void elementalSubstractionMatrix – функция поэлементного вычитания матриц
	void elementalSubstractionVector – функция поэлементного вычитания векторов, которая изменяет первый входной вектор
	vector<vector<double>> Transponse – транспонирование матрицы-строки
	vector<vector<double>> Transponse – транспонирование матрицы
	vector<vector<double>> matrixMultiply – матричное умножение матриц nx1 и 1xm
	vector<double> matrixMultiply – матричное умножение матриц 1xn и nxm
	vector<double> multiplyAdemara – поэлементное умножение векторов
	vector<double> ReLUDerivative – возвращает вектор производных ReLU в точках входного вектора
	void multiplyConstMatrix – умножение матрицы на константу
	void multiplyConstVector – умножение вектора на константу
	void DirectPassage – функция, в которой осуществляется прямой проход по нейронной сети:
	Вычисляются значения нейронов на первом скрытом слое
	Вычисляются значения нейронов на втором скрытом слое
	Вычисляются значения нейронов на выходном слое
	Вектор значений на выходном слое преобразуется в вектор вероятностей
	void BackPropogation – функция, в которой осуществляется обратный проход по нейронной сети:
	Высчитываются градиенты по всем весам на слоях
	LearningRate – скорость обучения нейронной сети
	Изменение весов на слоях в сторону уменьшения значения ошибки(минимума функции ошибки)
	void DirectPassageTest – прямой проход по нейронной сети для тестовой выборки (отличие от обычного прямого прохода в отсутствии запоминания промежуточных значений на слоях)
	double isCorrect – функция проверки совпадения предсказания нейронной сети и ожидаемого значения
	void TestTrain – функция проверки точности нейронной сети на тестовой выборке
	void Train – функция первичного обучения модели на обучающей выборке (веса берутся случайные). Веса в конце записываются в отдельные файлы
	void NextTrain – обучение модели на обучающей выборки с использованием весов, полученных на прошлой эпохе обучения
	void ReadDataPerson(vector<double>& inputX) – чтение файла, в котором находится изображение, которое ввел пользователь, где каждый пиксель переведен в численный вид
	void Anwer(vector<double>& ans) – функция определения ответа нейронной сети на пользовательском значении 
	void PersonNumbers() – функция, в которой пользователь вводит имя файла, где нарисована цифра, которую должная предугадать нейронная сеть
Принцип работы нейронной сети
На вход нейронной сети подается вектор «яркости» конкретных пикселей на изображении 28x28. Далее на первом скрытом слое значение на каждом нейроне вычисляется как значение каждого нейрона на входном слое, умноженное на соответствующий ему вес плюс свободный вес bias. Происходит «активация» нейронов с помощью нелинейной функции ReLU. На втором скрытом слое значения получаются абсолютно также, только вместо входного слоя используется первый скрытый слой. Происходит «активация» нейронов с помощью нелинейной функции ReLU. На выходном слое значения вычисляются так же, как и на прошлых слоях, но без функции активации. Вместо нее выступает функция SoftMax, после которой на выходе получается вектор вероятностей. Далее с помощью обратного прохода по нейронной сети мы изменяем веса на слоях: вычисляются векторы частных производных – градиенты по цепному правилу дифференцирования функции от нескольких переменных. Затем изменяются веса по формуле: 
ω_(i+1)= ω_i- α·δE/δω
Где ω_(i+1) - новый вектор весов, ω_i – старый вектор весов, α – скорость обучения, δE/δω – вектор частных производных функции ошибки по весам.

Если пользователь захочет дать на вход нейронной сети свой рисунок, то он может воспользоваться функцией PersonNumbers(), где он введет имя файла, которое необходимо предугадать. Перед этим файл необходимо поместить в папку numbers в файле проекта. 
